---

# LocalAPI.AI

![GitHub stars](https://img.shields.io/github/stars/vam876/LocalAPI.ai?style=social)
![GitHub forks](https://img.shields.io/github/forks/vam876/LocalAPI.ai?style=social)
![GitHub watchers](https://img.shields.io/github/watchers/vam876/LocalAPI.ai?style=social)
![GitHub repo size](https://img.shields.io/github/repo-size/vam876/LocalAPI.ai)
![GitHub language count](https://img.shields.io/github/languages/count/vam876/LocalAPI.ai)
![GitHub top language](https://img.shields.io/github/languages/top/vam876/LocalAPI.ai)
![GitHub last commit](https://img.shields.io/github/last-commit/vam876/LocalAPI.ai?color=red)

---
[‰∏≠Êñá](./README.zh.md)  
---

# LocalAPI.AI ü§ñ

## Tool Overview üåü  
**LocalAPI.AI** is a dedicated local AI management tool designed specifically for **Ollama**, while also being compatible with other mainstream local AI deployment platforms such as vLLM, LM Studio, and llama.cpp.  
It integrates features such as intelligent conversation, text generation, and multimodal image recognition, and provides comprehensive model management capabilities, including model copying, deletion, pulling, updating, creation, and quantization. Additionally, it supports flexible parameter settings to meet the diverse needs of users.

---

## Key Features üöÄ

## Detailed Explanation of Core Features  

### 1. **Support for macOS/Windows Desktop Clients**  
‚Ä¢ Offers dedicated desktop clients for macOS and Windows with a clean and user-friendly interface.  
‚Ä¢ Supports one-click activation of an authentication middleware for AI services, eliminating the need for complex configurations and avoiding cross-origin issues. Users can directly access AI services through a browser.  

### 2. **Intelligent Conversation Interface**  
‚Ä¢ Provides a natural language interaction interface, allowing users to converse with AI models using everyday language.  
‚Ä¢ Offers real-time feedback, intelligent responses, and suggestions, while also supporting chat history saving and prompt control.  

### 3. **Advanced Text Generation**  
‚Ä¢ Leverages powerful language generation models to create articles, code, poetry, and other types of content.  
‚Ä¢ Provides real-time performance metrics, including loading time and processing speed, to help users optimize their experience.  

### 4. **Model Management System**  
‚Ä¢ Supports multi-model management, including copying, deleting, pulling, updating, creating, and quantizing models.  
‚Ä¢ Offers flexible parameter settings to meet the needs of individual developers and enterprise users.  

### 5. **Additional Features to Discover**  
‚Ä¢ **Privacy and Security**: All data processing is performed locally, and offline usage is supported to ensure data privacy.  
‚Ä¢ **Reliable Deployment**: Provides a secure deployment method with a reserved Nginx authentication interface to further enhance data security.  
‚Ä¢ **Community Support**: Join the LocalAPI.AI community to access the latest feature updates and technical support.  

---

## Use Cases üéØ

‚Ä¢ **AI Enthusiasts**  
  Offers a simple and intuitive interaction experience, suitable for users interested in exploring and experimenting with AI.  

‚Ä¢ **Students and Beginners**  
  Easy to use, ideal for assisting learning and daily Q&A, helping to improve learning efficiency.  

‚Ä¢ **Individual Developers**  
  Suitable for creative validation and small project development, providing flexible parameter settings and robust feature support.  

‚Ä¢ **Enterprise Applications**  
  Although primarily designed for individual users, its multi-model support and high performance also make it suitable for enterprise-level services, ensuring data security and privacy protection.  

---

## üåê Online Usage  
No installation is required. Visit [LocalAPI.AI](http://www.localapi.ai) to access all features.  
Users only need to configure their browser and enable cross-origin support to enjoy a seamless online AI interaction experience.

---

## üì• Client Download  
The tool supports three major mainstream operating systems: macOS üçé, Windows üíª, and Linux üêß.  
Users can start the desktop client and run the service in a browser without resolving cross-origin issues, enabling efficient local AI interaction.

---

## üõ†Ô∏è Deployment Guide  

### ‚ö° Quick Deployment Method  
Download the **Ollama_WEB.html** file and open it in the Firefox browser. Directly access `/Ollama_WEB.html`.  
**Note**: Refer to [http://localapi.ai/tutorial](http://localapi.ai/tutorial) to enable Ollama cross-origin support and temporarily disable Firefox's cross-origin restrictions.

---

### ‚ö° Web Service Deployment Method  
Deploy the **Ollama_WEB.html** file to a web server for quick access:  

1. Download the [Ollama_WEB.html](https://github.com/vam876/LocalAPI.ai/releases) file.  
2. Deploy the file to a web server and access `/Ollama_WEB.html`.

---

### üì∏ **Feature Demonstrations**

#### 1. **Support for macOS/Windows Desktop Clients**  
Supports one-click activation of a secure authentication middleware for AI services, allowing browser-based usage without resolving cross-origin issues.  
![image](https://github.com/user-attachments/assets/245669ca-41b9-41d1-977a-1b0e31cf0465)

*Figure 1: macOS/Windows/Linux Desktop Client, Supporting One-Click Activation of Authentication Middleware*

---

#### 2. **Intelligent Conversation Interface**  
Engage in natural conversations with AI models to obtain instant answers and insights.  
![image](https://github.com/user-attachments/assets/906114a6-6b85-4f51-89c6-f5dc98bb4919)

*Figure 2: Intelligent Conversation Interface, Supporting Natural Language Interaction and Real-Time Feedback*

---

#### 3. **Advanced Text Generation and Image Recognition**    
![image](https://github.com/user-attachments/assets/6eea22c3-469e-4262-9433-d8f24e692528)
![image](https://github.com/user-attachments/assets/1c98a3e6-5ac5-4227-99e1-4f52c5e1684c)

*Figure 3: Advanced Text Generation Feature, Supporting Various Content Creation Types*

---

#### 4. **Model Management System**  
Easily manage and configure multiple AI models to meet different needs.  
![image](https://github.com/user-attachments/assets/ea417711-1ae5-4fb0-bff5-dc223dda5a53)

*Figure 4: Model Management Interface, Supporting Model Copying, Deleting, Updating, and More*

---

#### 5. **Additional Features to Discover**  
Reliable deployment method with a reserved Nginx authentication interface and custom HTTP headers to ensure complete privacy and security.  
![image](https://github.com/user-attachments/assets/6c2ab630-dcbd-4630-8630-3b73993b5c04)

*Figure 5: Deployment Interface, Supporting Nginx Authentication Interface and Custom HTTP Headers for Data Privacy and Security*

---

## Summary  

**LocalAPI.AI** is a powerful, secure, and user-friendly local AI management tool.  
It not only provides deep integration with Ollama but also supports multiple mainstream local AI deployment platforms such as vLLM, LM Studio, and llama.cpp. Through one-click activation of authentication middleware, comprehensive model management features, and highly flexible parameter settings, it provides users with an efficient, convenient, and secure experience.  

Whether you're an AI enthusiast, student, developer, or enterprise user, you can quickly get started and fully utilize its powerful features to achieve secure and efficient local AI interaction!

---

**Welcome to Join the LocalAPI.AI Community!**  

‚Ä¢ **GitHub Repository**: [https://github.com/vam876/LocalAPI.ai](https://github.com/vam876/LocalAPI.ai)  
‚Ä¢ **Contact Information**: Vamjun8@gmail.com
