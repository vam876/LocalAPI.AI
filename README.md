# LocalAPI.ai

![GitHub stars](https://img.shields.io/github/stars/vam876/LocalAPI.ai?style=social)
![GitHub forks](https://img.shields.io/github/forks/vam876/LocalAPI.ai?style=social)
![GitHub watchers](https://img.shields.io/github/watchers/vam876/LocalAPI.ai?style=social)
![GitHub repo size](https://img.shields.io/github/repo-size/vam876/LocalAPI.ai)
![GitHub language count](https://img.shields.io/github/languages/count/vam876/LocalAPI.ai)
![GitHub top language](https://img.shields.io/github/languages/top/vam876/LocalAPI.ai)
![GitHub last commit](https://img.shields.io/github/last-commit/vam876/LocalAPI.ai?color=red)

---
[‰∏≠Êñá](./README.zh.md)

---

# LocalAPI.AI ü§ñ

## Tool Overview üåü  
**LocalAPI.AI** is a dedicated local AI management tool specifically designed for **Ollama**, and it is also compatible with a variety of mainstream local AI deployment platforms such as vLLM, LM Studio, and llama.cpp.  
It integrates intelligent conversation, text generation, multimodal image recognition, and other functions, and provides comprehensive model management support, including advanced functions such as model copying, deletion, pulling, updating, creation, and model quantization, as well as flexible parameter settings to meet the needs of different users.

---

## Features üöÄ

‚Ä¢ **Designed for Ollama and Compatible with Multiple Models**  
  Deeply integrated with the core functions of Ollama, it is also compatible with a variety of local AI deployment platforms such as vLLM, LM Studio, llama.cpp, Ollama, Mozilla-Llamafile, Jan Al, Cortex API, Local-LLM, LiteLLM, GPT4All, etc., to meet the diverse needs of different users.

‚Ä¢ **Quick Setup of Local Model Service Authentication Middleware**  
  Users can simply download the macOS, Windows, or Linux client to set up the authentication middleware for local model services with one click. There is no need for complex configuration, and the model service can be quickly started and secured.

‚Ä¢ **Comprehensive Model Management Functions**  
  It provides advanced functions such as model copying, deletion, pulling, updating, creation, and model quantization, and supports flexible parameter settings to meet the diverse needs of users ranging from individual developers to enterprise users.

‚Ä¢ **Deeply Optimized Static Files**  
  We have deeply optimized the built static files, which are ultimately merged into a single HTML file. With just one HTML file, powerful local AI API interaction capabilities can be achieved without complex deployment and ready-to-use.

‚Ä¢ **Responsive Design, Mobile Compatible**  
  It supports access from a variety of devices and is compatible with mobile devices, allowing users to start AI interaction experiences anytime, anywhere through their smartphones or tablets.

‚Ä¢ **Security and Privacy Protection**  
  All data processing is completed locally and will not be uploaded to the cloud or third-party servers, ensuring data security. After the initial load, users can use it offline without an internet connection and have full control over their data.

‚Ä¢ **Online Usage**  
  There is no need to install any programs. By visiting [LocalAPI.ai](http://www.localapi.ai), users can access the full range of functions. By simply configuring the browser and enabling cross-origin support, a smooth online AI interaction experience can be achieved in the browser.

---

## Main Functions üöÄ

‚Ä¢ **Intelligent Conversation**  
  Interact with AI models using natural language to obtain intelligent answers and suggestions. Messages provide instant feedback, support saving chat history in the browser, and offer highly flexible parameter and prompt control.

‚Ä¢ **Text Generation**  
  It supports the generation of various types of text content to improve creative efficiency and has already supported some multimodal models for image content recognition. It provides instant performance metric feedback, intuitively displaying loading time, processing time, evaluation time, token generation speed, etc.

‚Ä¢ **Model Management**  
  It provides comprehensive model management functions, including advanced functions such as model copying, deletion, pulling, updating, creation, and model quantization, and supports flexible parameter settings to meet diverse needs.

‚Ä¢ **Prompt Library**  
  It offers a rich prompt library that users can freely import or export personal AI prompts. It supports online editing and one-click application to chat conversations, helping users to inspire creativity and improve the quality of AI output.

---

## Use Cases üéØ

‚Ä¢ **AI Enthusiasts**  
  Provides an easy-to-use interactive experience suitable for users interested in AI.

‚Ä¢ **Students and Beginners**  
  Easy to get started, suitable for assisting learning and daily Q&A.

‚Ä¢ **Individual Developers**  
  Suitable for creative validation and small project development.

‚Ä¢ **Enterprise-Level Applications**  
  Although mainly aimed at individual users, its multi-model support and high performance also make it suitable for enterprise-level service applications.

---

## üåê Online Usage  
There is no need to install any programs. By visiting [LocalAPI.ai](http://www.localapi.ai), users can access the full range of functions.  
Users only need to simply configure the browser and enable cross-origin support to achieve a smooth online AI interaction experience in the browser.

---

## üì• Client Download  
The tool supports the three major mainstream operating systems: macOS üçé, Windows üíª, and Linux üêß.  
Users can start the service through the desktop application and run the service in the browser without solving cross-origin issues, achieving efficient local AI interaction.

---

## üõ†Ô∏è Deployment Guide  

### ‚ö° Quick Deployment Method  
Download the **LocalAPI_WEB.html** file and open it with Firefox browser to directly access `/LocalAPI_WEB.html`.  
**Note**: You need to refer to [http://localapi.ai/tutorial](http://localapi.ai/tutorial) to enable Ollama cross-origin support and temporarily disable the cross-origin restrictions of the Firefox browser.

---

### ‚ö° Web Service Deployment Method  
Deploy the **LocalAPI_WEB.html** file to a web service for quick access:  

1. Download the [LocalAPI_WEB.html](https://github.com/vam876/LocalAPI.ai/releases) file.  
2. Or deploy the file to a web server and access `/LocalAPI_WEB.html`.

---

## üì∏ **Function Demonstration**

#### 1. **Support for macOS/Windows Desktop**  
Supports one-click activation of a secure authentication middleware for AI services, allowing usage through the browser without solving cross-origin issues.  
![image](https://github.com/user-attachments/assets/245669ca-41b9-41d1-977a-1b0e31cf0465)

*Figure 1: macOS/Windows/Linux desktop, supporting one-click activation of authentication middleware*

---

#### 2. **Intelligent Conversation Interface**  
Engage in natural conversations with AI models to obtain instant answers and insights.  
![image](https://github.com/user-attachments/assets/906114a6-6b85-4f51-89c6-f5dc98bb4919)

*Figure 2: Intelligent conversation interface, supporting natural language interaction and instant feedback*

---

#### 3. **Advanced Text Generation and Image Recognition**    

![image](https://github.com/user-attachments/assets/6eea22c3-469e-4262-9433-d8f24e692528)
![image](https://github.com/user-attachments/assets/1c98a3e6-5ac5-4227-99e1-4f52c5e1684c)
*Figures 3-4: Advanced text generation functions, supporting creation of various content types*

---

#### 4. **Model Management System**  
Easily manage and configure multiple AI models to meet different needs.  
![image](https://github.com/user-attachments/assets/6c2ab630-dcbd-4630-8630-3b73993b5c04)

*Figure 5: Model management interface, supporting operations such as model copying, deletion, and updating*

---

#### 5. **More Features to Discover**  
Reliable deployment methods, with reserved Nginx authentication interfaces and custom HTTP request headers to ensure complete privacy and security.  
![image](https://github.com/user-attachments/assets/28df4993-0e5c-496f-8589-b2b5ea03953f)


*Figure 6: Deployment interface, supporting Nginx authentication interfaces and custom HTTP request headers to ensure data privacy and security*

---

## Summary  

**LocalAPI.AI** is a powerful, secure, and easy-to-use local AI management tool.  
It not only provides deep integration for Ollama but is also compatible with a variety of mainstream local AI deployment platforms. By enabling one-click setup of authentication middleware, comprehensive model management functions, and highly flexible parameter settings, it offers users an efficient, convenient, and secure experience.  

Whether you are an AI enthusiast, student, developer, or enterprise user, you can quickly get started with LocalAPI.AI and fully utilize its powerful functions to achieve secure and efficient local AI interaction!

---
## About the Source Code

Our **LocalAPI_WEB.html** is built with **Vite + React + TypeScript** as a static file, while **LocalAPI.ai Desktop** is developed using **Ruts**. Currently, most of the code is written by AI, and we are in the process of optimizing it. Once the optimization is complete, we will open-source the entire codebase. You can now edit or adjust **LocalAPI_WEB.html** using your preferred code editor.

---

**Welcome to use LocalAPI.AI**  

‚Ä¢ **GitHub Repository**: [https://github.com/vam876/LocalAPI.ai](https://github.com/vam876/LocalAPI.ai)  

‚Ä¢ **Contact**: Vamjun8@gmail.com

‚Ä¢ **Official Website**: LocalAPI.ai
