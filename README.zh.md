 # LocalAPI.ai 

![GitHub stars](https://img.shields.io/github/stars/vam876/LocalAPI.ai?style=social)
![GitHub forks](https://img.shields.io/github/forks/vam876/LocalAPI.ai?style=social)
![GitHub watchers](https://img.shields.io/github/watchers/vam876/LocalAPI.ai?style=social)
![GitHub repo size](https://img.shields.io/github/repo-size/vam876/LocalAPI.ai)
![GitHub language count](https://img.shields.io/github/languages/count/vam876/LocalAPI.ai)
![GitHub top language](https://img.shields.io/github/languages/top/vam876/LocalAPI.ai)
![GitHub last commit](https://img.shields.io/github/last-commit/vam876/LocalAPI.ai?color=red)
---
[english](./README.md)

---
# LocalAPI.AI 🤖

## 工具概述 🌟  
**LocalAPI.AI** 是一款专为 **Ollama** 量身打造的本地 AI 管理工具，同时兼容 vLLM、LM Studio、llama.cpp 等多种主流本地 AI 部署平台。  
它集成了智能对话、文本生成、多模态图像识别等功能，并提供全面的模型管理支持，包括模型复制、删除、拉取、更新、创建以及模型量化等高级功能，同时支持弹性参数设置，满足不同用户的需求。

---


## 功能特点  🚀

• **专为 Ollama 打造，兼容多种模型**  
  深度集成 Ollama 的核心功能，同时兼容 vLLM、LM Studio、llama.cpp、Ollama、Mozilla-Llamafile、Jan Al、Cortex API、Local-LLM、LiteLLM、GPT4All 等多种本地 AI 部署平台，满足不同用户的多样化需求。

• **快速搭建本地模型服务的认证中间层**  
  用户只需下载 macOS、Windows 或 Linux 客户端，即可一键搭建本地模型服务的认证中间层，无需复杂配置，快速启动并保护模型服务的安全。

• **全面的模型管理功能**  
  提供模型复制、删除、拉取、更新、创建以及模型量化等高级功能，支持弹性参数设置，满足从个人开发者到企业用户的多样化需求。

• **深度优化的静态文件**  
  我们对构建后的静态文件进行深度优化，最终融合成为一个 HTML 文件，通过一个 HTML 即可实现强大的本地 AI API 交互能力，无需复杂部署，开箱即用。

• **响应式设计，兼容移动端**  
  支持多种设备访问，适配移动端设备，随时随地通过手机或平板开启 AI 交互体验。

• **安全性与隐私保护**  
  所有数据处理均在本地完成，不会上传至云端或第三方服务器，确保数据安全。首次加载后，用户可以在无网络环境下使用，随时随地掌控数据。

• **在线使用**  
  无需安装任何程序，访问 LocalAPI.ai 即可使用全量功能。用户只需简单配置浏览器并开启跨域支持，即可在浏览器中实现流畅的在线 AI 交互体验。

---

## 主要功能  🚀

• **智能对话**  
  通过自然语言与 AI 模型交互，获取智能回答和建议。消息提供即时反馈，支持聊天记录保存在浏览器，并提供高度弹性的参数和提示词控制。

• **文本生成**  
  支持生成各种类型的文本内容，提高创作效率，并已支持部分多模态模型进行图片内容识别。提供即时的性能指标反馈，直观展示加载耗时、处理时间、评估耗时、token 生成速度等。

• **模型管理**  
  提供全面的模型管理功能，包括模型复制、删除、拉取、更新、创建以及模型量化等高级功能，同时支持弹性参数设置，满足多样化需求。

• **提示词库**  
  提供丰富的提示词库，用户可以自由导入或导出个人 AI 提示词，支持在线编辑和一键应用到聊天对话，帮助用户激发创意并提高 AI 输出质量。

---

## 适用场景  🎯

• **AI 爱好者**  
  提供简单易用的交互体验，适合对 AI 感兴趣的用户。

• **学生和初学者**  
  易于上手，适合辅助学习和日常问答。

• **个人开发者**  
  适合进行创意验证、小型项目开发。

• **企业级应用**  
  虽然主要面向个人用户，但其多模型支持和高效性能也适合企业级服务应用。

---

## 🌐 在线使用  
无需安装任何程序，访问 [LocalAPI.ai](http://www.localapi.ai) 即可使用全量功能。  
用户只需简单配置浏览器并开启跨域支持，即可在浏览器中实现流畅的在线 AI 交互体验。

---

## 📥 客户端下载  
工具支持 macOS 🍎、Windows 💻 和 Linux 🐧 三大主流操作系统。  
用户可以通过桌面端程序启动后，在浏览器中运行服务，无需解决跨域问题，实现高效本地 AI 交互。

---

## 🛠️ 部署指南  

### ⚡ 极速部署方法  
下载 **LocalAPI_WEB.html** 文件，通过火狐 Firefox 浏览器打开，直接访问 `/LocalAPI_WEB.html`。  
**注意**：需要参考 [http://localapi.ai/tutorial](http://localapi.ai/tutorial) 开启 Ollama 跨域支持，并临时关闭 Firefox 浏览器的跨域限制。


---


### ⚡ Web 服务部署方法  
将 **LocalAPI_WEB.html** 文件部署到 Web 服务即可快速访问：  

1. 下载 [LocalAPI_WEB.html](https://github.com/vam876/LocalAPI.ai/releases) 文件。  
2. 或将文件部署到 Web 服务器，访问 `/LocalAPI_WEB.html`。

---

## 📸 **功能展示**

#### 1. **支持 macOS/Windows 桌面端**  
支持为 AI 服务一键开启安全的认证中间层，无需解决跨域问题，即可通过浏览器进行使用。  
![image](https://github.com/user-attachments/assets/319d3fe5-79f9-4197-894f-7dd495439fd3)


*图 1: macOS/Windows/Linux 桌面端，支持一键开启认证中间层*

---

#### 2. **智能对话界面**  
与 AI 模型进行自然对话，获取即时答案和见解。  
![image](https://github.com/user-attachments/assets/43d0e900-8cb9-4203-8db7-3b0a4439ddfc)


*图 2: 智能对话界面，支持自然语言交互和即时反馈*

---

#### 3. **高级文本生成与图像识别**    
![image](https://github.com/user-attachments/assets/230a3c72-ade9-4489-9d68-f97480e719b0)

![image](https://github.com/user-attachments/assets/e3169f2a-7f0c-48ca-b527-7e6be6df49d8)

*图 3-4: 高级文本生成功能，支持多种内容类型创作*

---

#### 4. **模型管理系统**  
轻松管理和配置多个 AI 模型，满足不同需求。  
![image](https://github.com/user-attachments/assets/5d6edfbe-bec3-4fa2-bb2d-8aba532afd74)


*图 5: 模型管理界面，支持模型复制、删除、更新等操作*

---

#### 5. **更多功能等您发现**  
可靠的部署方式，预留 Nginx 认证接口和自定义HTTP请求头，确保完全的隐私和安全。  
![image](https://github.com/user-attachments/assets/7074f2df-a010-45ce-89bc-c13c7750fa7a)


*图 6: 部署界面，支持 Nginx 认证接口和自定义HTTP请求头，确保数据隐私和安全*

---

## 总结  

**LocalAPI.AI** 是一款功能强大、安全可靠且易于使用的本地 AI 管理工具。  
它不仅为 Ollama 提供了深度集成，还兼容多种主流本地 AI 部署平台。通过一键搭建认证中间层、全面的模型管理功能以及高度弹性的参数设置，为用户提供了高效、便捷、安全的使用体验。  

无论是 AI 爱好者、学生、开发者还是企业用户，都能通过 LocalAPI.AI 快速上手并充分利用其强大的功能，实现本地 AI 交互的安全与高效！  

---
## 关于源代码

我们的 **LocalAPI_WEB.html** 是使用 **Vite + React + TypeScript** 构建的静态文件代码，而 **LocalAPI.ai Desktop** 是用 **Python** 开发的。目前，代码的大部分内容由 AI 编写，我们正在对其进行优化。优化完成后，我们会将全部代码开源。您现在可以使用代码编辑器对 **LocalAPI_WEB.html** 进行编辑或调整。

---

**欢迎使用 LocalAPI.AI**  

• **GitHub 仓库**: [https://github.com/vam876/LocalAPI.ai](https://github.com/vam876/LocalAPI.ai)  

• **联系方式**: Vamjun8@gmail.com

• **官方网站**: LocalAPI.ai
