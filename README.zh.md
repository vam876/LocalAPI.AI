# LocalAPI.AI

![GitHub stars](https://img.shields.io/github/stars/vam876/LocalAPI.ai?style=social)
![GitHub forks](https://img.shields.io/github/forks/vam876/LocalAPI.ai?style=social)
![GitHub watchers](https://img.shields.io/github/watchers/vam876/LocalAPI.ai?style=social)
![GitHub repo size](https://img.shields.io/github/repo-size/vam876/LocalAPI.ai)
![GitHub language count](https://img.shields.io/github/languages/count/vam876/LocalAPI.ai)
![GitHub top language](https://img.shields.io/github/languages/top/vam876/LocalAPI.ai)
![GitHub last commit](https://img.shields.io/github/last-commit/vam876/LocalAPI.ai?color=red)
---
[English](./README.md)  
---

# LocalAPI.AI 🤖

## 工具概述 🌟  
**LocalAPI.AI** 是一款专为 **Ollama** 量身打造的本地 AI 管理工具，同时兼容 vLLM、LM Studio、llama.cpp 等多种主流本地 AI 部署平台。  
它集成了智能对话、文本生成、多模态图像识别等功能，并提供全面的模型管理支持，包括模型复制、删除、拉取、更新、创建以及模型量化等高级功能，同时支持弹性参数设置，满足不同用户的需求。

---

## 功能亮点 🚀



## 核心功能详解 

### 1. **支持 macOS/Windows 桌面端**  
• 提供专为 macOS 和 Windows 设计的桌面客户端，界面简洁易用。  
• 支持一键开启 AI 服务的认证中间层，无需复杂配置，避免跨域问题，直接通过浏览器访问 AI 服务。  

### 2. **智能对话界面**  
• 提供自然语言交互界面，用户可以通过日常语言与 AI 模型进行对话。  
• 支持即时反馈，提供智能回答和建议，同时支持聊天记录保存和提示词控制。  

### 3. **高级文本生成**  
• 使用强大的语言生成模型，支持生成文章、代码、诗歌等多种类型的内容。  
• 提供实时的性能指标反馈，包括加载时间、处理速度等，帮助用户优化使用体验。  

### 4. **模型管理系统**  
• 支持多模型管理，包括模型的复制、删除、拉取、更新、创建和量化等操作。  
• 提供弹性参数设置，满足个人开发者和企业用户的多样化需求。  

### 5. **更多功能等您发现**  
• **隐私与安全**：所有数据处理均在本地完成，支持离线使用，确保数据隐私。  
• **可靠部署**：提供可靠的部署方式，预留 Nginx 认证接口，进一步提升数据安全性。  
• **社区支持**：加入 LocalAPI.AI 社区，获取最新功能更新和技术支持。  

---

## 适用场景 🎯

• **AI 爱好者**  
  提供简单易用的交互体验，适合对 AI 感兴趣的用户探索和尝试。  

• **学生和初学者**  
  易于上手，适合辅助学习和日常问答，帮助提升学习效率。  

• **个人开发者**  
  适合进行创意验证、小型项目开发，提供灵活的参数设置和强大的功能支持。  

• **企业级应用**  
  虽然主要面向个人用户，但其多模型支持和高效性能也适合企业级服务应用，确保数据安全和隐私保护。  

---

## 🌐 在线使用  
无需安装任何程序，访问 [LocalAPI.ai](http://www.localapi.ai) 即可使用全量功能。  
用户只需简单配置浏览器并开启跨域支持，即可在浏览器中实现流畅的在线 AI 交互体验。

---

## 📥 客户端下载  
工具支持 macOS 🍎、Windows 💻 和 Linux 🐧 三大主流操作系统。  
用户可以通过桌面端程序启动后，在浏览器中运行服务，无需解决跨域问题，实现高效本地 AI 交互。

---

## 🛠️ 部署指南  

### ⚡ 极速部署方法  
下载 **Ollama_WEB.html** 文件，通过火狐 Firefox 浏览器打开，直接访问 `/Ollama_WEB.html`。  
**注意**：需要参考 [http://localapi.ai/tutorial](http://localapi.ai/tutorial) 开启 Ollama 跨域支持，并临时关闭 Firefox 浏览器的跨域限制。

---

### ⚡ Web 服务部署方法  
将 **Ollama_WEB.html** 文件部署到 Web 服务即可快速访问：  

1. 下载 [Ollama_WEB.html](https://github.com/vam876/LocalAPI.ai/releases) 文件。  
2. 或将文件部署到 Web 服务器，访问 `/Ollama_WEB.html`。

---
### 📸 **功能展示**

#### 1. **支持 macOS/Windows 桌面端**  
支持为 AI 服务一键开启安全的认证中间层，无需解决跨域问题，即可通过浏览器进行使用。  
![image](https://github.com/user-attachments/assets/319d3fe5-79f9-4197-894f-7dd495439fd3)


*图 1: macOS/Windows/Linux 桌面端，支持一键开启认证中间层*

---

#### 2. **智能对话界面**  
与 AI 模型进行自然对话，获取即时答案和见解。  
![image](https://github.com/user-attachments/assets/43d0e900-8cb9-4203-8db7-3b0a4439ddfc)


*图 2: 智能对话界面，支持自然语言交互和即时反馈*

---

#### 3. **高级文本生成与图像识别**    
![image](https://github.com/user-attachments/assets/230a3c72-ade9-4489-9d68-f97480e719b0)

![image](https://github.com/user-attachments/assets/e3169f2a-7f0c-48ca-b527-7e6be6df49d8)

*图 3-4: 高级文本生成功能，支持多种内容类型创作*

---

#### 4. **模型管理系统**  
轻松管理和配置多个 AI 模型，满足不同需求。  
![image](https://github.com/user-attachments/assets/5d6edfbe-bec3-4fa2-bb2d-8aba532afd74)


*图 5: 模型管理界面，支持模型复制、删除、更新等操作*

---

#### 5. **更多功能等您发现**  
可靠的部署方式，预留 Nginx 认证接口和自定义HTTP请求头，确保完全的隐私和安全。  
![image](https://github.com/user-attachments/assets/7074f2df-a010-45ce-89bc-c13c7750fa7a)


*图 6: 部署界面，支持 Nginx 认证接口和自定义HTTP请求头，确保数据隐私和安全*

---

## 总结  

**LocalAPI.AI** 是一款功能强大、安全可靠且易于使用的本地 AI 管理工具。  
它不仅为 Ollama 提供了深度集成，还兼容多种主流本地 AI 部署平台。通过一键搭建认证中间层、全面的模型管理功能以及高度弹性的参数设置，为用户提供了高效、便捷、安全的使用体验。  

无论是 AI 爱好者、学生、开发者还是企业用户，都能通过 LocalAPI.AI 快速上手并充分利用其强大的功能，实现本地 AI 交互的安全与高效！  

---

**欢迎加入 LocalAPI.AI 的社区！**  

• **GitHub 仓库**: [https://github.com/vam876/LocalAPI.ai](https://github.com/vam876/LocalAPI.ai)  
• **联系方式**: Vamjun8@gmail.com
